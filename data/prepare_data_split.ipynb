{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "# LF input and output\n",
    "x_l1 = np.loadtxt('./narrow/matter_power_564_Box1000_Part750_15_Box1000_Part3000_z0/train_input_fidelity_0.txt')\n",
    "y_l1 = np.loadtxt('./narrow/matter_power_564_Box1000_Part750_15_Box1000_Part3000_z0/train_output_fidelity_0.txt')\n",
    "k_l1 = np.loadtxt('./narrow/matter_power_564_Box1000_Part750_15_Box1000_Part3000_z0/kf.txt')\n",
    "\n",
    "x_l2 = np.loadtxt('./narrow/matter_power_564_Box250_Part750_15_Box1000_Part3000_z0/train_input_fidelity_0.txt')\n",
    "y_l2 = np.loadtxt('./narrow/matter_power_564_Box250_Part750_15_Box1000_Part3000_z0/train_output_fidelity_0.txt')\n",
    "k_l2 = np.loadtxt('./narrow/matter_power_564_Box250_Part750_15_Box1000_Part3000_z0/kf.txt')\n",
    "\n",
    "# HF input and output\n",
    "x_h = np.loadtxt('./narrow/matter_power_564_Box250_Part750_15_Box1000_Part3000_z0/train_input_fidelity_1.txt')\n",
    "y_h = np.loadtxt('./narrow/matter_power_564_Box250_Part750_15_Box1000_Part3000_z0/train_output_fidelity_1.txt')\n",
    "k_h = np.loadtxt('./narrow/matter_power_564_Box250_Part750_15_Box1000_Part3000_z0/kf.txt')\n",
    "\n",
    "dir_LHA = 'N_LHA_z0'\n",
    "dir_LHB = 'N_LHB_z0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1 and L2 split\n",
    "\n",
    "k_mid = k_l1[k_l1.shape[0] // 2]\n",
    "\n",
    "# locate the index of k_mid in k_l1\n",
    "idx = np.where(k_l1 == k_mid)[0][0]\n",
    "y_l1A = y_l1[:,:idx]\n",
    "k_l1A = k_l1[:idx]\n",
    "\n",
    "# locate the index of k_mid in k_l2\n",
    "idx = np.where(k_l2 == k_mid)[0][0]\n",
    "y_l2B = y_l2[:,idx:]\n",
    "k_l2B = k_l2[idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the split data\n",
    "dir_L1 = \"N_L1A_z0\"\n",
    "dir_L2 = \"N_L2B_z0\"\n",
    "# make the directory if not exist\n",
    "\n",
    "if not os.path.exists(dir_L1):\n",
    "    os.makedirs(dir_L1)\n",
    "if not os.path.exists(dir_L2):\n",
    "    os.makedirs(dir_L2)\n",
    "\n",
    "np.savetxt(dir_L1 + '/train_output.txt', y_l1A)\n",
    "np.savetxt(dir_L2 + '/train_output.txt', y_l2B)\n",
    "\n",
    "# also copy the input data and k data\n",
    "np.savetxt(dir_L1 + '/train_input.txt', x_l1)\n",
    "np.savetxt(dir_L2 + '/train_input.txt', x_l2)\n",
    "\n",
    "np.savetxt(dir_L1 + '/kf.txt', k_l1A)\n",
    "np.savetxt(dir_L2 + '/kf.txt', k_l2B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the L1 input and find the ones (indices) that are in the HF input\n",
    "indices = []\n",
    "for i in range(len(x_l1)):\n",
    "    if x_l1[i] in x_h:\n",
    "        indices.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[144, 145, 146, 168, 169, 170, 195, 196, 197, 204, 205, 206, 336, 337, 338]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.59976085, -1.56002463, -1.5202884 , -1.48055217, -1.44081595,\n",
       "       -1.40107972, -1.36134349, -1.32160727, -1.28187104, -1.24213481,\n",
       "       -1.20239859, -1.16266236, -1.12292613, -1.08318991, -1.04345368,\n",
       "       -1.00371745, -0.96398123, -0.924245  , -0.88450877, -0.84477255,\n",
       "       -0.80503632, -0.76530009, -0.72556387, -0.68582764, -0.64609141,\n",
       "       -0.60635519, -0.56661896, -0.52688273, -0.48714651, -0.44741028,\n",
       "       -0.40767406, -0.36793783, -0.3282016 , -0.28846538, -0.24872915,\n",
       "       -0.20899292, -0.1692567 , -0.12952047, -0.08978424, -0.05004802,\n",
       "       -0.01031179,  0.02942444,  0.06916066,  0.10889689,  0.14863312,\n",
       "        0.18836934,  0.22810557,  0.2678418 ,  0.30757802,  0.34731425,\n",
       "        0.38705048,  0.4267867 ,  0.46652293,  0.50625916,  0.54599538,\n",
       "        0.58573161,  0.62546784,  0.66520406,  0.70494029,  0.74467652,\n",
       "        0.78441274,  0.82414897,  0.8638852 ,  0.90362142])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_and_stitch(k_l1, y_l1, k_l2, y_l2, k_h): # y_l1 and y_l2 are 2D arrays\n",
    "    # index of middle k value\n",
    "    middle = len(k_h) // 2\n",
    "    # interpolate the L1 output to the first half HF k values\n",
    "    y_l1_interp = np.array([np.interp(k_h[:middle], k_l1, y_l1[i,:]) for i in range(len(y_l1))])\n",
    "    # interpolate the L1 output to the second half HF k values\n",
    "    y_l2_interp = np.array([np.interp(k_h[middle:], k_l2, y_l2[i,:]) for i in range(len(y_l2))])\n",
    "    # stitch the two interpolated outputs together\n",
    "    y_interp = np.concatenate((y_l1_interp, y_l2_interp), axis=1)\n",
    "    return y_interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut y_l1 and y_l2 and stitch them together\n",
    "y_lf = cut_and_stitch(k_l1, y_l1[indices], k_l2, y_l2[indices], k_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_l1A_H = y_l1A[indices]\n",
    "y_l2B_H = y_l2B[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset for LF-HF correlation\n",
    "# input: x_h, y_l1[indices], y_l2[indices] (concatenate)\n",
    "x_xyl1A = np.concatenate((x_h, y_l1A_H), axis=1)\n",
    "x_xyl2B = np.concatenate((x_h, y_l2B_H), axis=1)\n",
    "\n",
    "# output: y_h \n",
    "y_hA = y_h[:, :idx]\n",
    "y_hB = y_h[:, idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataset\n",
    "\n",
    "if not os.path.exists(dir_LHA):\n",
    "    os.makedirs(dir_LHA)\n",
    "if not os.path.exists(dir_LHB):\n",
    "    os.makedirs(dir_LHB)\n",
    "\n",
    "np.savetxt(dir_LHA + '/train_input.txt', x_xyl1A)\n",
    "np.savetxt(dir_LHA + '/train_output.txt', y_hA)\n",
    "\n",
    "np.savetxt(dir_LHB + '/train_input.txt', x_xyl2B)\n",
    "np.savetxt(dir_LHB + '/train_output.txt', y_hB)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
